---
layout: home
title: About
nav_exclude: false
permalink: index.html
seo:
  type: Course
  name: Introduction to ML Safety
---

# Introduction to ML Safety

ML systems are rapidly increasing in size, are acquiring new capabilities, and are increasingly deployed in high-stakes settings. As with other powerful technologies, safety for ML should be a leading research priority. In this course we'll discuss how researchers can shape the process that will lead to strong AI systems and steer that process in a safer direction. We'll cover various technical topics to reduce existential risks (X-Risks) from strong AI, namely withstanding hazards ("Robustness"), identifying hazards ("Monitoring"), reducing inherent ML system hazards ("Alignment"), and reducing deployment hazards ("Systemic Safety"). At the end, we will zoom out and discuss additional abstract existential hazards and discuss how to increase safety without unintended side effects.

## Prerequisites
This is a topics course in machine learning, so a solid background in Machine Learning and Deep Learning is necessary.

## Syllabus

Hazard Analysis: Disaster Risk Equation, A Systems View of Safety, Black Swans

Robustness: Adversaries, Long Tails

Monitoring: Anomalies, Uncertainty, Trojans, and Emergent Behavior

Alignment: Honesty, Power-seeking, and Value Learning

Systemic Safety: ML for Improved Epistemics, ML for Improved Cyberdefense

Other Sources of X-Risk: Future Scenarios, Avoiding Capabilities Externalities
