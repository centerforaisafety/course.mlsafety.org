---
title: Additional Existential Risk Discussion
---

19
: X-Risk Overview
    : [ğŸ¥](#media-popup){:class="youtube" media-id="3eP2WcFE20w"}, [ğŸ›](https://docs.google.com/presentation/d/19IuBw7GsO6MEeOQIAbY6imDnWLSLT4Fzk2PAW6xq_gA/edit?usp=sharing), [ğŸ“–](https://github.com/centerforaisafety/Intro_to_ML_Safety)
: arguments for x-risk

20
: Possible Existential Hazards
  : [ğŸ¥](#media-popup){:class="youtube" media-id="k1jV0Mx1xT4"}, [ğŸ›](https://docs.google.com/presentation/d/1tp65f22ZhWoKdie6VNrh2nY1dWLoK_0WXSSXzdBYLt4/edit?usp=sharing), [ğŸ“–](https://github.com/centerforaisafety/Intro_to_ML_Safety)
: weaponization, proxy gaming, treacherous turn, deceptive alignment, value lock-in, persuasive AI

21
: Safety-Capabilities Balance
  : [ğŸ¥](#media-popup){:class="youtube" media-id="sJm7LNMtA4E"}, [ğŸ›](https://docs.google.com/presentation/d/1P2VsZClM6YsK_vYtO66Yt-JeKlCFBABK-4ieZf0F2B4/edit?usp=sharing), [ğŸ“–](https://github.com/centerforaisafety/Intro_to_ML_Safety)
: theories of impact, differential technological progress, capabilities externalities

22
: Natural Selection Favors AIs over Humans
  : [ğŸ›](), [ğŸ“–](https://github.com/centerforaisafety/Intro_to_ML_Safety)
: TBC Fall 2022; fitness comparisons, Lewontin's conditions, multiple agents and variation, generalized Darwinism, artificial vs natural selection, evolutionary mechanisms for altruism, internal constraints, incentives, Leviathan

23
: Review and Conclusion
  : [ğŸ¥](#media-popup){:class="youtube" media-id="_fu7lKRt0Ac"}, [ğŸ›](https://docs.google.com/presentation/d/1EL9ogIdzapL8_tZMMTw0CfhusRmHtnqA9uh3Wcoutj4/edit?usp=sharing), [ğŸ“](https://drive.google.com/file/d/1bKAyPeWSz4_jr3vdm2rHKrWu_xe-CNv_/view?usp=sharing)
: pillars of ML safety research, task-train-deploy pipeline
