---
title: Additional Existential Risk Discussion
---

19
: X-Risk Overview
    : [🛝](https://docs.google.com/presentation/d/19IuBw7GsO6MEeOQIAbY6imDnWLSLT4Fzk2PAW6xq_gA/edit?usp=sharing), [📖](https://github.com/centerforaisafety/Intro_to_ML_Safety)
: arguments for x-risk

20
: Possible Existential Hazards
  : [🛝](https://docs.google.com/presentation/d/1tp65f22ZhWoKdie6VNrh2nY1dWLoK_0WXSSXzdBYLt4/edit?usp=sharing), [📖](https://github.com/centerforaisafety/Intro_to_ML_Safety)
: weaponization, proxy gaming, treacherous turn, deceptive alignment, value lock-in, persuasive AI

21
: Safety-Capabilities Balance
  : [🛝](https://docs.google.com/presentation/d/1P2VsZClM6YsK_vYtO66Yt-JeKlCFBABK-4ieZf0F2B4/edit?usp=sharing), [📖](https://github.com/centerforaisafety/Intro_to_ML_Safety)
: theories of impact, differential technological progress, capabilities externalities

22
: Risks from Human-AI Coevolution
  : [🛝](), [📖](https://github.com/centerforaisafety/Intro_to_ML_Safety)
: TBC Fall 2022; selection pressures, pressure for information propagation, internal constraints, mesa optimization, objective selection pressures, Leviathan, symbiosis

23
: Review and Conclusion
  : [🛝](https://docs.google.com/presentation/d/1EL9ogIdzapL8_tZMMTw0CfhusRmHtnqA9uh3Wcoutj4/edit?usp=sharing), [📝](https://drive.google.com/file/d/1bKAyPeWSz4_jr3vdm2rHKrWu_xe-CNv_/view?usp=sharing)
: pillars of ML safety research, task-train-deploy pipeline
