---
title: Additional Existential Risk Discussion
---

17
: X-Risk
    : [üñ•Ô∏è slides](https://docs.google.com/presentation/d/19IuBw7GsO6MEeOQIAbY6imDnWLSLT4Fzk2PAW6xq_gA/edit?usp=sharing)
: arguments for x-risk

18
: Possible Existential Hazards
  : [üñ•Ô∏è slides](https://docs.google.com/presentation/d/1tp65f22ZhWoKdie6VNrh2nY1dWLoK_0WXSSXzdBYLt4/edit?usp=sharing)
: weaponization, proxy misspecification, treacherous turn, deceptive alignment, value lock-in, persuasive AI

19
: Safety-Capabilities Balance
  : [üñ•Ô∏è slides](https://docs.google.com/presentation/d/1P2VsZClM6YsK_vYtO66Yt-JeKlCFBABK-4ieZf0F2B4/edit?usp=sharing)
: theories of impact, differential technological progress, capabilities externalities

20
: Review and Conclusion
  : [üñ•Ô∏è slides](https://docs.google.com/presentation/d/1EL9ogIdzapL8_tZMMTw0CfhusRmHtnqA9uh3Wcoutj4/edit?usp=sharing), [üìù questions](https://www.overleaf.com/read/mfwgrcvtxqhx)
: reliability and alignment, pillars of ML safety research
