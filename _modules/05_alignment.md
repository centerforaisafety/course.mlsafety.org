---
title: Alignment
---

13
: Honest Models
    : [🎥](#media-popup){:class="youtube" media-id="r24Gj3quBXc"}, [🛝](https://docs.google.com/presentation/d/1eVO4-HiPlxkOgySEPBv_H-TKkkZYpC5buySBeo1C6eU/edit?usp=sharing), [📖](https://github.com/centerforaisafety/Intro_to_ML_Safety)
: truthful vs. honest, inverse scaling, instances of model dishonesty

14
: Power Aversion
  : [🛝]()
: TBC fall 2022

15
: Machine Ethics
  : [🎥](#media-popup){:class="youtube" media-id="FeX3gOV7Tj0"}, [🛝](https://docs.google.com/presentation/d/1yibQ-RBSMnejAdEk8iMTTzYyTFmMiRasOLwdvvahZkE/edit?usp=sharing), [📖](https://github.com/centerforaisafety/Intro_to_ML_Safety), [⌨️](https://colab.research.google.com/drive/1WyzvZR9Vd3R1QiJpKnYgnzCTp00xqnGF?usp=sharing)
: normative ethics background, human values, value learning with comparisons, translating moral knowledge into action, moral parliament, value clarification

