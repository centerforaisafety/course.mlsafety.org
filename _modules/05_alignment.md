---
title: Alignment
---

13
: Honest Models
    : [üñ•Ô∏è](https://docs.google.com/presentation/d/1eVO4-HiPlxkOgySEPBv_H-TKkkZYpC5buySBeo1C6eU/edit?usp=sharing)
: truthful vs. honest, inverse scaling, instances of model dishonesty

14
: Intrasystem Goals or Power Aversion
  : [üñ•Ô∏è]()
: in preparation

15
: Machine Ethics
  : [üñ•Ô∏è](https://docs.google.com/presentation/d/1yibQ-RBSMnejAdEk8iMTTzYyTFmMiRasOLwdvvahZkE/edit?usp=sharing), [‚å®Ô∏è](https://colab.research.google.com/drive/1RJabhcBelfXcXHkur2sjM_7oQUyIDirr?usp=sharing)
: normative ethics background, human values, value learning with comparisons, translating moral knowledge into action, value lock-in, safelife, attainable utility preservation
