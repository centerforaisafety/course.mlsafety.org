---
title: Alignment
---

13
: **Honest Models**
: [üé•](#media-popup){:class="youtube" media-id="r24Gj3quBXc"}, [üñ•Ô∏è](https://docs.google.com/presentation/d/1eVO4-HiPlxkOgySEPBv_H-TKkkZYpC5buySBeo1C6eU/edit?usp=sharing)
: _truthful vs. honest, inverse scaling, instances of model dishonesty_

14
: **Power Aversion**
: [üñ•Ô∏è](https://docs.google.com/presentation/d/1bI0WNfPg9B0LK7h5Oe6lciminrzsJv_z7anzVV1TO2E/edit?usp=sharing)
: _measuring power; the power-seeeking argument; power penalties_

15
: **Machine Ethics**
: [üé•](#media-popup){:class="youtube" media-id="FeX3gOV7Tj0"}, [üñ•Ô∏è](https://docs.google.com/presentation/d/1yibQ-RBSMnejAdEk8iMTTzYyTFmMiRasOLwdvvahZkE/edit?usp=sharing), [‚å®Ô∏è](https://colab.research.google.com/drive/1C7pQEsxbIjrRpriqPffCiQW43ffyIi2b?usp=share_link)
: _normative ethics background, human values, value learning with comparisons, translating moral knowledge into action, moral parliament, value clarification_
