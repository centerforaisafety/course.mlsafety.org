---
title: Robustness 
questions: https://drive.google.com/file/d/1ypEmCfBjDw3e0CS7urfb8pmwj1goAk97/view?usp=sharing
---

6
: Adversarial Robustness
    : [ğŸ¥](#media-popup){:class="youtube" media-id="wIX00bZ173k"}, [ğŸ›](https://docs.google.com/presentation/d/1HzloChC0XElQkCTI181CN6OaYcVNnB5l37sfuANkcq0/edit?usp=sharing), [ğŸ“–](https://github.com/centerforaisafety/Intro_to_ML_Safety/blob/master/Adversarial%20Robustness/main.md), [âŒ¨ï¸](https://colab.research.google.com/drive/1ezV-jXyPgXDMSo6LqXyRgV_f2ky0cCFH?copy)
: optimization pressure, PGD, untargeted vs targeted attacks, adversarial evaluation, white box vs black box, transferability, unforeseen attacks, text attacks, robustness certificates

7
: Black Swan Robustness
  : [ğŸ¥](#media-popup){:class="youtube" media-id="9mEp0mk0mpA"}, [ğŸ›ï¸](https://docs.google.com/presentation/d/1uW7hNstJAq7_lSyk3yP8yTSjN85itESbDHFRi1F4wiw/edit?usp=sharing), [ğŸ“–](https://github.com/centerforaisafety/Intro_to_ML_Safety/blob/master/Black%20Swan%20Robustness/main.md)
: stress tests, train-test mismatch, adversarial distribution shifts, simulated scenarios for robustness
